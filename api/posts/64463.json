{"title":"读取 txt 文件并生成词云图","slug":"读取txt文件并生成词云图","date":"2020-10-03","updated":"2020-10-03","comments":true,"path":"api/posts/64463.json","excerpt":null,"cover":"https://s1.ax1x.com/2020/10/03/03jWIU.md.png","covers":["https://s1.ax1x.com/2020/10/03/03jWIU.md.png","https://s1.ax1x.com/2020/10/03/03jZK1.png","https://s1.ax1x.com/2020/10/03/03jWIU.md.png"],"content":"<h2 id=\"读取 txt 文件并生成词云图\"><a href=\"# 读取 txt 文件并生成词云图\" class=\"headerlink\" title=\"读取 txt 文件并生成词云图\"></a>读取 txt 文件并生成词云图</h2><p><a href=\"https://imgchr.com/i/03jWIU\"><img src=\"https://s1.ax1x.com/2020/10/03/03jWIU.md.png\" alt=\"03jWIU.md.png\"></a></p>\n<ul>\n<li><h3 id=\"一 - 下载第三方模块\"><a href=\"# 一 - 下载第三方模块\" class=\"headerlink\" title=\"(一)下载第三方模块\"></a>(一)下载第三方模块</h3><h6 id=\"1-wordcloud- 它把我们带权重的关键词渲染成词云。\"><a href=\"#1-wordcloud- 它把我们带权重的关键词渲染成词云。\" class=\"headerlink\" title=\"1.wordcloud: 它把我们带权重的关键词渲染成词云。\"></a>1.wordcloud: 它把我们带权重的关键词渲染成词云。</h6><h6 id=\"2-jieba：是一个分词模块，因为我是从一个 txt 文本里提取关键词，所以需要 -jieba- 来分词并统计词频。如果是已经有了现成的数据，不再需要它。\"><a href=\"#2-jieba：是一个分词模块，因为我是从一个 txt 文本里提取关键词，所以需要 -jieba- 来分词并统计词频。如果是已经有了现成的数据，不再需要它。\" class=\"headerlink\" title=\"2.jieba：是一个分词模块，因为我是从一个 txt 文本里提取关键词，所以需要 jieba 来分词并统计词频。如果是已经有了现成的数据，不再需要它。\"></a>2.jieba：是一个分词模块，因为我是从一个 txt 文本里提取关键词，所以需要 jieba 来分词并统计词频。如果是已经有了现成的数据，不再需要它。</h6><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install wordcloud</span><br><span class=\"line\"></span><br><span class=\"line\">pip install jieba</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><h3 id=\"（二）WordCloud 类的使用\"><a href=\"#（二）WordCloud 类的使用\" class=\"headerlink\" title=\"（二）WordCloud 类的使用\"></a>（二）WordCloud 类的使用</h3></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>WordCloud 构造方法的参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>font_path</td>\n<td>字体路径，需要展现什么字体就把该字体路径 + 后缀名写上，如：font_path = ‘黑体.ttf’</td>\n</tr>\n<tr>\n<td>width</td>\n<td>输出的画布宽度，默认为 400 像素</td>\n</tr>\n<tr>\n<td>height</td>\n<td>输出的画布高度，默认为 200 像素</td>\n</tr>\n<tr>\n<td>prefer_horizontal</td>\n<td>词语水平方向排版出现的频率，默认 0.9 （所以词语垂直方向排版出现频率为 0.1 ）</td>\n</tr>\n<tr>\n<td>mask</td>\n<td>如果参数为空，则使用二维遮罩绘制词云。如果 mask 非空，设置的宽高值将被忽略，遮罩形状被 mask 取代。除全白（#FFFFFF）的部分将不会绘制，其余部分会用于绘制词云。如：bg_pic = imread(‘读取一张图片.png’)，背景图片的画布一定要设置为白色（#FFFFFF），然后显示的形状为不是白色的其他颜色。可以用 ps 工具将自己要显示的形状复制到一个纯白色的画布上再保存。</td>\n</tr>\n<tr>\n<td>scale</td>\n<td>按照比例进行放大画布，如设置为 1.5，则长和宽都是原来画布的 1.5 倍。</td>\n</tr>\n<tr>\n<td>min_font_size</td>\n<td>显示的最小的字体大小</td>\n</tr>\n<tr>\n<td>font_step</td>\n<td>字体步长，如果步长大于 1，会加快运算但是可能导致结果出现较大的误差。</td>\n</tr>\n<tr>\n<td>max_words</td>\n<td>显示的词的最大个数</td>\n</tr>\n<tr>\n<td>stopwords</td>\n<td>设置需要屏蔽的词，如果为空，则使用内置的 STOPWORDS</td>\n</tr>\n<tr>\n<td>background_color</td>\n<td>背景颜色，如 background_color=‘white’, 背景颜色为白色。</td>\n</tr>\n<tr>\n<td>max_font_size</td>\n<td>显示的最大的字体大小</td>\n</tr>\n<tr>\n<td>mode</td>\n<td>当参数为“RGBA”并且 background_color 不为空时，背景为透明。</td>\n</tr>\n<tr>\n<td>relative_scaling</td>\n<td>词频和字体大小的关联性</td>\n</tr>\n<tr>\n<td>color_func</td>\n<td>生成新颜色的函数，如果为空，则使用 self.color_func</td>\n</tr>\n<tr>\n<td>regexp</td>\n<td>使用正则表达式分隔输入的文本</td>\n</tr>\n<tr>\n<td>collocations</td>\n<td>是否包括两个词的搭配</td>\n</tr>\n<tr>\n<td>colormap</td>\n<td>给每个单词随机分配颜色，若指定 color_func，则忽略该方法。</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<h3 id=\"数据准备\"><a href=\"# 数据准备\" class=\"headerlink\" title=\"数据准备\"></a>数据准备 </h3><p><strong> 小说《中国合伙人 1.txt》，约 3400 行</strong><br><a href=\"https://imgchr.com/i/03jZK1\"><img src=\"https://s1.ax1x.com/2020/10/03/03jZK1.png\" alt=\"03jZK1.png\"></a></p>\n<h3 id=\"源代码\"><a href=\"# 源代码\" class=\"headerlink\" title=\"源代码\"></a>源代码</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> jieba</span><br><span class=\"line\"><span class=\"keyword\">import</span> jieba.analyse</span><br><span class=\"line\"><span class=\"keyword\">import</span> codecs</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> Counter</span><br><span class=\"line\"><span class=\"keyword\">from</span> wordcloud <span class=\"keyword\">import</span> WordCloud</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> wordcloud</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建停用词列表</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">stopwordlist</span>():</span></span><br><span class=\"line\">    stopwords = [line.strip() <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> open(<span class=\"string\">&#x27;../ 结巴分词 /hit_stopwords.txt&#x27;</span>,encoding=<span class=\"string\">&#x27;UTF-8&#x27;</span>).readlines()]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> stopwords</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 对句子进行中文分词</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">seg_depart</span>(<span class=\"params\">sentence</span>):</span></span><br><span class=\"line\">    print(<span class=\"string\">&#x27; 正在分词 &#x27;</span>)</span><br><span class=\"line\">    sentence_depart = jieba.cut(sentence.strip())</span><br><span class=\"line\">    <span class=\"comment\"># 创建一个停用词列表</span></span><br><span class=\"line\">    stopwords = stopwordlist()</span><br><span class=\"line\">    <span class=\"comment\"># 输出结果为 outstr</span></span><br><span class=\"line\">    outstr = <span class=\"string\">&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"comment\">#     去停用词</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> word <span class=\"keyword\">in</span> sentence_depart:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> word <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> stopwords:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> word != <span class=\"string\">&#x27;\\t&#x27;</span>:</span><br><span class=\"line\">                outstr += word</span><br><span class=\"line\">                outstr += <span class=\"string\">&quot; &quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> outstr</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">print(<span class=\"string\">&quot; 读取文件并生成词云图 &quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">create_word_cloud</span>(<span class=\"params\">file</span>):</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 读取文件内容</span></span><br><span class=\"line\">    content = codecs.open(file,<span class=\"string\">&#x27;r&#x27;</span>,<span class=\"string\">&#x27;gbk&#x27;</span>).read()</span><br><span class=\"line\">  <span class=\"comment\"># 去停用词</span></span><br><span class=\"line\">    content = seg_depart(content)</span><br><span class=\"line\">    <span class=\"comment\"># 结巴分词</span></span><br><span class=\"line\">    wordlist = jieba.cut(content)</span><br><span class=\"line\">    wl = <span class=\"string\">&quot; &quot;</span>.join(wordlist)</span><br><span class=\"line\"></span><br><span class=\"line\">    print(wl)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 配置词云图</span></span><br><span class=\"line\">    wc = wordcloud.WordCloud(</span><br><span class=\"line\">    <span class=\"comment\">#     设置背景颜色</span></span><br><span class=\"line\">        background_color=<span class=\"string\">&#x27;white&#x27;</span>,</span><br><span class=\"line\">    <span class=\"comment\">#     设置最大显示的词数</span></span><br><span class=\"line\">        max_words=<span class=\"number\">100</span>,</span><br><span class=\"line\">    <span class=\"comment\">#     设置字体路径</span></span><br><span class=\"line\">        font_path = <span class=\"string\">&#x27;C:\\Windows\\Fonts\\msyh.ttc&#x27;</span>,</span><br><span class=\"line\">        height=<span class=\"number\">1200</span>,</span><br><span class=\"line\">        width=<span class=\"number\">1600</span>,</span><br><span class=\"line\">    <span class=\"comment\">#     设置字体最大值</span></span><br><span class=\"line\">        max_font_size=<span class=\"number\">300</span>,</span><br><span class=\"line\">    <span class=\"comment\">#     设置有多少种配色方案，即多少种随机生成状态</span></span><br><span class=\"line\">        random_state=<span class=\"number\">50</span>,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 生成词云图</span></span><br><span class=\"line\">    myword = wc.generate(wl)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 展示词云图</span></span><br><span class=\"line\">    plt.imshow(myword)</span><br><span class=\"line\">    plt.axis(<span class=\"string\">&quot;off&quot;</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">create_word_cloud(<span class=\"string\">&quot; 中国合伙人 1.txt&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"生成词云图\"><a href=\"# 生成词云图\" class=\"headerlink\" title=\"生成词云图\"></a>生成词云图</h3><p><a href=\"https://imgchr.com/i/03jWIU\"><img src=\"https://s1.ax1x.com/2020/10/03/03jWIU.md.png\" alt=\"03jWIU.md.png\"></a></p>\n","url":"/posts/64463/","min2read":3,"word4post":877,"prev_post":{"title":"有道翻译反爬虫机制","url":"/posts/52867/"},"next_post":{"title":"Hello World","url":"/posts/16107/"},"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" data-id=\"读取 txt 文件并生成词云图\" href = \"#\"><span class=\"toc-number\">1.</span> <span class=\"toc-text\">读取 txt 文件并生成词云图</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" data-id=\"一 - 下载第三方模块\" href = \"#\"><span class=\"toc-number\">1.1.</span> <span class=\"toc-text\">(一)下载第三方模块</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" data-id=\"1-wordcloud- 它把我们带权重的关键词渲染成词云。\" href = \"#\"><span class=\"toc-number\">1.1.0.0.1.</span> <span class=\"toc-text\">1.wordcloud: 它把我们带权重的关键词渲染成词云。</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" data-id=\"2-jieba：是一个分词模块，因为我是从一个 txt 文本里提取关键词，所以需要 -jieba- 来分词并统计词频。如果是已经有了现成的数据，不再需要它。\" href = \"#\"><span class=\"toc-number\">1.1.0.0.2.</span> <span class=\"toc-text\">2.jieba：是一个分词模块，因为我是从一个 txt 文本里提取关键词，所以需要 jieba 来分词并统计词频。如果是已经有了现成的数据，不再需要它。</span></a></li></ol></li></ol></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" data-id=\"（二）WordCloud 类的使用\" href = \"#\"><span class=\"toc-number\">1.2.</span> <span class=\"toc-text\">（二）WordCloud 类的使用</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" data-id=\"数据准备\" href = \"#\"><span class=\"toc-number\">1.3.</span> <span class=\"toc-text\">数据准备 </span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" data-id=\"源代码\" href = \"#\"><span class=\"toc-number\">1.4.</span> <span class=\"toc-text\">源代码</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" data-id=\"生成词云图\" href = \"#\"><span class=\"toc-number\">1.5.</span> <span class=\"toc-text\">生成词云图</span></a></li></ol></li></ol>","categories":[{"name":"python","path":"api/categories/python.json","url":"/categories/python/"},{"name":"自然语言处理","path":"api/categories/自然语言处理.json","url":"/categories/自然语言处理/"},{"name":"词云图","path":"api/categories/词云图.json","url":"/categories/词云图/"}],"tags":[{"name":"python","path":"api/tags/python.json","url":"/tags/python/"},{"name":"中文分词","path":"api/tags/中文分词.json","url":"/tags/中文分词/"},{"name":"词云图","path":"api/tags/词云图.json","url":"/tags/词云图/"},{"name":"Jieba分词","path":"api/tags/Jieba分词.json","url":"/tags/Jieba分词/"}]}